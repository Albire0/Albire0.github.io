<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>基于LSTM的三分类情感分析系统 - Albire0的博客</title><meta name="Description" content="这是我的全新 Hugo 网站"><meta property="og:title" content="基于LSTM的三分类情感分析系统" />
<meta property="og:description" content="基于LSTM的三分类情感分析系统 史博文 2018211147 2019211315 设计流程 对于一个字，词的情感分析模型，设计实验比较字的效果" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://albire0.github.io/post/first/" /><meta property="og:image" content="https://albire0.github.io/logo.png"/><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-11-13T21:14:22+08:00" />
<meta property="article:modified_time" content="2022-11-13T23:32:16+08:00" /><meta property="og:site_name" content="我的网站" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://albire0.github.io/logo.png"/>

<meta name="twitter:title" content="基于LSTM的三分类情感分析系统"/>
<meta name="twitter:description" content="基于LSTM的三分类情感分析系统 史博文 2018211147 2019211315 设计流程 对于一个字，词的情感分析模型，设计实验比较字的效果"/>
<meta name="application-name" content="我的网站">
<meta name="apple-mobile-web-app-title" content="我的网站"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://albire0.github.io/post/first/" /><link rel="stylesheet" href="/css/style.min.c57300a31a581e27c9bdbbeba0f40607.css" integrity="md5-xXMAoxpYHifJvbvroPQGBw=="><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "基于LSTM的三分类情感分析系统",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/albire0.github.io\/post\/first\/"
        },"genre": "post","keywords": "NLP","wordcount":  2419 ,
        "url": "https:\/\/albire0.github.io\/post\/first\/","datePublished": "2022-11-13T21:14:22+08:00","dateModified": "2022-11-13T23:32:16+08:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Albire0"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="auto" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Albire0的博客">Albire0的博客</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/post/"> 文章 </a><a class="menu-item" href="/tags/" title="123"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Albire0的博客">Albire0的博客</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/post/" title="">文章</a><a class="menu-item" href="/tags/" title="123">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="page single special"><h1 class="single-title animate__animated animate__pulse animate__faster">基于LSTM的三分类情感分析系统</h1><h2 class="single-subtitle">史博文-2018211147-2019211315</h2><div class="content" id="content"><h1 id="基于lstm的三分类情感分析系统">基于LSTM的三分类情感分析系统</h1>
<p><em>史博文 2018211147 2019211315</em></p>
<h2 id="设计流程">设计流程</h2>
<p>对于一个字，词的情感分析模型，设计实验比较字的效果是否好于词，流程为</p>
<ol>
<li>数据处理
<ol>
<li>读取文件中的文本和对应的标签，最大文本的长度</li>
<li>观察标签的分布情况，发现3，2，1的数量要明显小于4，5</li>
<li>将3，2，1集合为1类，4，5分别为第2，第3类</li>
<li>按字/词的方式，构造word2id字典</li>
<li>将文本中的字/词按word2id字典做映射，截断到最大文本长</li>
</ol>
</li>
<li>数据处理（词向量）
<ol>
<li>分词后训练Word2Vec模型</li>
<li>创建词语字典，并返回每个词语的索引，词向量，以及每个句子所对应的词语索引</li>
<li>准备词向量矩阵</li>
</ol>
</li>
<li>搭建模型
<ol>
<li>按照下面的模型结构搭建</li>
<li>模型的优化器选用adam，学习率默认</li>
<li>模型的评估方法为loss和acc</li>
<li>模型的损失函数为稀疏交叉熵</li>
</ol>
</li>
<li>训练模型
<ol>
<li>训练集和验证集的比例为9：1</li>
<li>直接将x，y整体输入模型中，不使用生成器</li>
</ol>
</li>
<li>对每个模型绘制loss和acc的图</li>
<li>观察结果，分析</li>
</ol>
<h2 id="数据处理">数据处理</h2>
<p>数据的处理有两种情况，字的部分通过data.py文件中的函数，词的处理通过MyTokenizer类</p>
<p>在data.py中，描述如下</p>
<table>
<thead>
<tr>
<th>作用</th>
<th>函数名</th>
</tr>
</thead>
<tbody>
<tr>
<td>将句子转化为token</td>
<td>def sentence_to_token(sentence, word2token: dict):-&gt;tokens</td>
</tr>
<tr>
<td>对每一条句子做补0或截断操作</td>
<td>def padding_or_truncate_text(item):-&gt;texts</td>
</tr>
<tr>
<td>读取训练数据</td>
<td>def read_train_data()</td>
</tr>
<tr>
<td>获得各项分类的权重</td>
<td>def get_classweights(y:list[int]):</td>
</tr>
<tr>
<td>获取word2id的字典</td>
<td>def get_word2id_json(sen_list):</td>
</tr>
<tr>
<td>将所有的星级转化为标签分类</td>
<td>def get_labels(stars):</td>
</tr>
<tr>
<td>将好评的星级转化为3个分类中的一个</td>
<td>def to_label(star):</td>
</tr>
<tr>
<td>统计各个star的出现频率</td>
<td>def calculate_star(stars):</td>
</tr>
<tr>
<td>将所有句子转化为tokens</td>
<td>def get_result(text_a, word2token):</td>
</tr>
</tbody>
</table>
<p>MyTokenizer类中，描述如下</p>
<p>初始化函数</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span> <span style="color:#66d9ef">def</span> __init__(self, char_level, max_word<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, oov_token<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;unk&gt;&#34;</span>, lower<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>                 filters<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;!&#34;#$%&amp;()*+,-./:;&lt;=&gt;?@[</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">]^_`{|}~</span><span style="color:#ae81ff">\t\n</span><span style="color:#e6db74">&#39;</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Tokenizer的初始化,返回单例
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param char_level:False按词去分,True 按字去分
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param max_word:最多分词的个数,默认是为-1,是所有
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param oov_token:out of vocab的单词对应的token
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param lower: 是否全部转化为小写 默认为True
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param filters: filters字符串内,是所有不参与分词的字符 默认为 &#39;!&#34;#$%&amp;()*+,-./:;&lt;=&gt;?@[</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">]^_`{|}~</span><span style="color:#ae81ff">\t\n</span><span style="color:#e6db74">&#39;
</span></span></span></code></pre></div><p>单例构造</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __new__(cls, <span style="color:#f92672">*</span>args, <span style="color:#f92672">**</span>kwargs):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        借助new方法 实现单例模式,这是因为new执行后,才是init执行
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        @:return 返回MyTokenizer单例
</span></span></span></code></pre></div><p>获取Mytokenizer的构造参数</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span> <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_config</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        获取Tokenizer的组装属性,并打印
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :return:返回Tokenizer的组装属性,type:dict
</span></span></span></code></pre></div><p>把所有的句子变成word_level的</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">text_to_wordlevel</span>(self,texts:list[str]):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        把普通的中文文本,转换为以词为单位,并保存
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param texts: :param texts: 文章 shape为(list[sentence])
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        比如:[&#34;飘渺孤鸿影，漏断人初静&#34;,”想当年，金戈铁马，气吞万里如虎“]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :return:以词为单位的文本新数组
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(<span style="color:#e6db74">&#34;word_level_input.txt&#34;</span>):
</span></span><span style="display:flex;"><span>            f <span style="color:#f92672">=</span> open(<span style="color:#e6db74">&#34;word_level_input.txt&#34;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;r&#39;</span>)
</span></span><span style="display:flex;"><span>            buffers <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>readlines()
</span></span><span style="display:flex;"><span>            new_texts <span style="color:#f92672">=</span> [item<span style="color:#f92672">.</span>strip(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>) <span style="color:#66d9ef">for</span> item <span style="color:#f92672">in</span> buffers]
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            f <span style="color:#f92672">=</span> open(<span style="color:#e6db74">&#34;word_level_input.txt&#34;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;w&#39;</span>)
</span></span><span style="display:flex;"><span>            new_texts <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> index <span style="color:#f92672">in</span> tqdm(range(<span style="color:#ae81ff">0</span>, len(texts))):
</span></span><span style="display:flex;"><span>                transformed_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(jieba<span style="color:#f92672">.</span>lcut(texts[index]))
</span></span><span style="display:flex;"><span>                f<span style="color:#f92672">.</span>writelines(transformed_text<span style="color:#f92672">+</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>                new_texts<span style="color:#f92672">.</span>append(transformed_text)
</span></span><span style="display:flex;"><span>        f<span style="color:#f92672">.</span>close()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> new_texts
</span></span></code></pre></div><p>利用text初始化tokenizer，得到字典</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fit_on_texts</span>(self, texts: list[str]):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        tokenizer获取对应的word2id,和id2word
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :param texts: 文章 shape为(list[sentence])
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        比如:[&#34;飘渺孤鸿影，漏断人初静&#34;,”想当年，金戈铁马，气吞万里如虎“]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        :return:word2id:dict,id2word:dict
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> isinstance(texts, list) <span style="color:#f92672">or</span> <span style="color:#f92672">not</span> isinstance(texts[<span style="color:#ae81ff">0</span>], str):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">raise</span> <span style="color:#a6e22e">Exception</span>(<span style="color:#e6db74">&#34;texts must be a list[str] type&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> self<span style="color:#f92672">.</span>__char_level:
</span></span><span style="display:flex;"><span>            new_texts <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>text_to_wordlevel(texts)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>__TOKENIZER<span style="color:#f92672">.</span>fit_on_texts(new_texts)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>__TOKENIZER<span style="color:#f92672">.</span>fit_on_texts(texts)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>word2id <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>__TOKENIZER<span style="color:#f92672">.</span>word_index
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>id2word <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>__TOKENIZER<span style="color:#f92672">.</span>index_word
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;model/word2id.json&#34;</span>, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;w&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>            json<span style="color:#f92672">.</span>dump(self<span style="color:#f92672">.</span>word2id, f)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;word_dict length:&#34;</span>, len(self<span style="color:#f92672">.</span>word2id))
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;word_dict saved in word2id.json&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>word2id, self<span style="color:#f92672">.</span>id2word
</span></span></code></pre></div><p>把所有的句子从词的层级转化为tokens</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fit_text_to_sequences</span>(self, texts):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    将所有句子转化为token
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :param texts:list of str,no separate in str, shape: list[str]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    比如:[&#34;飘渺孤鸿影，漏断人初静&#34;,”想当年，金戈铁马，气吞万里如虎“]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    :return:token_list:list of tokens,shape list[tokens]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> isinstance(texts, list) <span style="color:#f92672">or</span> <span style="color:#f92672">not</span> isinstance(texts[<span style="color:#ae81ff">0</span>], str):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">raise</span> <span style="color:#a6e22e">Exception</span>(<span style="color:#e6db74">&#34;texts must be a list[str] type&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> self<span style="color:#f92672">.</span>__char_level:
</span></span><span style="display:flex;"><span>        new_texts <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>text_to_wordlevel(texts)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>__TOKENIZER<span style="color:#f92672">.</span>texts_to_sequences(new_texts)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>__TOKENIZER<span style="color:#f92672">.</span>texts_to_sequences(texts)
</span></span></code></pre></div><h2 id="数据处理词向量">数据处理（词向量）</h2>
<p>在使用词向量的情况下，分词仍然是使用jieba分词，然后使用Data_wdvec.py这个文件，文件中的函数如下：</p>
<p>创建词语字典，并返回每个词语的索引，词向量，以及每个句子所对应的词语索引</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">word2vec_train</span>(text_sep):
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> Word2Vec(vector_size<span style="color:#f92672">=</span>vocab_dim,  <span style="color:#75715e"># 特征向量维度</span>
</span></span><span style="display:flex;"><span>                     min_count<span style="color:#f92672">=</span>n_exposures,  <span style="color:#75715e"># 可以对字典做截断. 词频少于min_count次数的单词会被丢弃掉, 默认值为5</span>
</span></span><span style="display:flex;"><span>                     window<span style="color:#f92672">=</span>window_size,  <span style="color:#75715e"># 窗口大小，表示当前词与预测词在一个句子中的最大距离是多少</span>
</span></span><span style="display:flex;"><span>                     workers<span style="color:#f92672">=</span>cpu_count,  <span style="color:#75715e"># 用于控制训练的并行数</span>
</span></span><span style="display:flex;"><span>                     )
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>build_vocab(text_sep)  <span style="color:#75715e"># 创建词汇表， 用来将 string token 转成 index</span>
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>train(text_sep, total_examples<span style="color:#f92672">=</span>model<span style="color:#f92672">.</span>corpus_count, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>save(<span style="color:#e6db74">&#39;Word2vec_model.pkl&#39;</span>)  <span style="color:#75715e"># 保存训练好的模型</span>
</span></span><span style="display:flex;"><span>    word2idx, word2vec, text_sep <span style="color:#f92672">=</span> create_dictionaries(model<span style="color:#f92672">=</span>model, text_sep<span style="color:#f92672">=</span>text_sep)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> word2idx, word2vec, text_sep  <span style="color:#75715e"># word_vectors字典类型{word:vec}</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_dictionaries</span>(model<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>, text_sep<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (text_sep <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>) <span style="color:#f92672">and</span> (model <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        gensim_dict <span style="color:#f92672">=</span> Dictionary()
</span></span><span style="display:flex;"><span>        gensim_dict<span style="color:#f92672">.</span>doc2bow(model<span style="color:#f92672">.</span>wv<span style="color:#f92672">.</span>key_to_index<span style="color:#f92672">.</span>keys(), allow_update<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        w2indx <span style="color:#f92672">=</span> {v: k <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span> <span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> gensim_dict<span style="color:#f92672">.</span>items()}  <span style="color:#75715e"># 所有频数超过10的词语的索引</span>
</span></span><span style="display:flex;"><span>        w2vec <span style="color:#f92672">=</span> {word: model<span style="color:#f92672">.</span>wv[word] <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> w2indx<span style="color:#f92672">.</span>keys()}  <span style="color:#75715e"># 所有频数超过10的词语的词向量</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">ToIdx</span>(texts):
</span></span><span style="display:flex;"><span>            data <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> sentence <span style="color:#f92672">in</span> texts:
</span></span><span style="display:flex;"><span>                new_txt <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> sentence:
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>                        new_txt<span style="color:#f92672">.</span>append(w2indx[word])
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">except</span>:
</span></span><span style="display:flex;"><span>                        new_txt<span style="color:#f92672">.</span>append(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>                data<span style="color:#f92672">.</span>append(new_txt)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> data
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        text_sep <span style="color:#f92672">=</span> ToIdx(text_sep)
</span></span><span style="display:flex;"><span>        text_sep <span style="color:#f92672">=</span> sequence<span style="color:#f92672">.</span>pad_sequences(text_sep, maxlen<span style="color:#f92672">=</span>truncate_thereshold)  <span style="color:#75715e"># 前方补0 为了进入LSTM的长度统一</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 每个句子所含词语对应的索引，所以句子中含有频数小于10的词语，索引为0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> w2indx, w2vec, text_sep
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#39;No data provided...&#39;</span>)
</span></span></code></pre></div><p>构建词向量矩阵</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_data</span>(word2idx, word2vec):
</span></span><span style="display:flex;"><span>    n_symbols <span style="color:#f92672">=</span> len(word2idx) <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>  <span style="color:#75715e"># 所有单词的索引数，频数小于10的词语索引为0，所以加1</span>
</span></span><span style="display:flex;"><span>    embedding_weights <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((n_symbols, vocab_dim))  <span style="color:#75715e"># 索引为0的词语，词向量全为0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> word, index <span style="color:#f92672">in</span> word2idx<span style="color:#f92672">.</span>items():  <span style="color:#75715e"># 从索引为1的词语开始，对每个词语对应其词向量</span>
</span></span><span style="display:flex;"><span>        embedding_weights[index, :] <span style="color:#f92672">=</span> word2vec[word]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> n_symbols, embedding_weights
</span></span></code></pre></div><h2 id="搭建模型">搭建模型</h2>
<ul>
<li>Embedding层
<ul>
<li>词嵌入，将index转化为vector</li>
</ul>
</li>
<li>Bi-LSTM层</li>
<li>Dense层
<ul>
<li>通过softmax激活，映射到多分类问题</li>
</ul>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">define_lstm_model</span>(word2token_len):
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> Sequential()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># input_shape是输入的维度特征,output_dim是输出词向量的维度，是一个随机初始化的过程</span>
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(Embedding(output_dim<span style="color:#f92672">=</span>output_dim,input_dim<span style="color:#f92672">=</span>word2token_len,mask_zero<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>))
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(Bidirectional(LSTM(LSTM_UNITS)))
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">3</span>,activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;softmax&#34;</span>))
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>compile(optimizer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;adam&#39;</span>,metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;accuracy&#34;</span>],loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sparse_categorical_crossentropy&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model
</span></span></code></pre></div><p>以及</p>
<ul>
<li>
<p>Embedding层</p>
<ul>
<li>词嵌入，将index转化为vector</li>
</ul>
</li>
<li>
<p>Conv1D层</p>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Conv1D(filters<span style="color:#f92672">=</span>filters,kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>,strides<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span></code></pre></div></li>
</ul>
</li>
<li>
<p>BiLSTM层</p>
</li>
<li>
<p>Dense层</p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">define_word_avg_model</span>(word2token,truncate_thereshold):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># input_shape是输入的维度特征,output_dim是输出词向量的维度，是一个随机初始化的过程</span>
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> Sequential()
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(Embedding(output_dim<span style="color:#f92672">=</span>output_dim,input_dim<span style="color:#f92672">=</span>len(word2token),input_length<span style="color:#f92672">=</span>truncate_thereshold,mask_zero<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 这里需要些模型</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># filters是输出的向量长</span>
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(Conv1D(filters<span style="color:#f92672">=</span>filters,kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>,strides<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(Bidirectional(LSTM(LSTM_UNITS)))
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">3</span>,activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;softmax&#34;</span>))
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>compile(optimizer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;adam&#39;</span>,metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;accuracy&#34;</span>],loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sparse_categorical_crossentropy&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model
</span></span></code></pre></div><p>若使用词向量，则使用单向LSTM，嵌入层使用词向量矩阵初始化</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">define_lstm_model</span>(n_symbols, embedding_weights, truncate_thereshold):
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;Defining a Simple Keras Model...&#39;</span>)
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> Sequential()  <span style="color:#75715e"># or Graph or whatever #堆叠</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 嵌入层将正整数（下标）转换为具有固定大小的向量</span>
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(Embedding(output_dim<span style="color:#f92672">=</span>output_dim,  <span style="color:#75715e"># 词向量的维度</span>
</span></span><span style="display:flex;"><span>                        input_dim<span style="color:#f92672">=</span>n_symbols,  <span style="color:#75715e"># 字典(词汇表)长度</span>
</span></span><span style="display:flex;"><span>                        mask_zero<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,  <span style="color:#75715e"># 确定是否将输入中的‘0’看作是应该被忽略的‘填充’（padding）值</span>
</span></span><span style="display:flex;"><span>                        weights<span style="color:#f92672">=</span>[embedding_weights], <span style="color:#75715e"># 词向量矩阵</span>
</span></span><span style="display:flex;"><span>                        input_length<span style="color:#f92672">=</span>truncate_thereshold))
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(LSTM(units<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tanh&#39;</span>))
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(Dropout(<span style="color:#ae81ff">0.5</span>))
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">3</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>))  <span style="color:#75715e"># 全连接层</span>
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>add(Activation(<span style="color:#e6db74">&#39;softmax&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;Compiling the Model...&#39;</span>)
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sparse_categorical_crossentropy&#39;</span>,
</span></span><span style="display:flex;"><span>                  optimizer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;adam&#39;</span>, metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
</span></span></code></pre></div><h2 id="训练模型">训练模型</h2>
<p>以word_lstm为例，首先定义checkpoint，以验证集的损失为单位，保存</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 定义一个CheckPoint</span>
</span></span><span style="display:flex;"><span>CheckPoint <span style="color:#f92672">=</span> ModelCheckpoint(save_best_only<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,monitor<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;val_loss&#34;</span>,filepath<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;model/word_lstm&#34;</span>)
</span></span></code></pre></div><p>然后训练，并且保存历史，以供后续制图</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>history <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit(pad_seqs,labels,epochs<span style="color:#f92672">=</span>EPOCHES,batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">32</span>,callbacks<span style="color:#f92672">=</span>[CheckPoint],class_weight<span style="color:#f92672">=</span>class_weights,validation_split<span style="color:#f92672">=</span><span style="color:#ae81ff">.1</span>)
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>save(<span style="color:#e6db74">&#34;model/word_lstm_model.h5&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;model/word_lstm_history.txt&#34;</span>,mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;wb&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>        pickle<span style="color:#f92672">.</span>dump(history<span style="color:#f92672">.</span>history,f)
</span></span></code></pre></div><h2 id="超参数说明">超参数说明</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>EPOCHES <span style="color:#f92672">=</span> <span style="color:#ae81ff">30</span>
</span></span><span style="display:flex;"><span>output_dim <span style="color:#f92672">=</span> <span style="color:#ae81ff">30</span>
</span></span><span style="display:flex;"><span>LSTM_UNITS <span style="color:#f92672">=</span> <span style="color:#ae81ff">30</span>
</span></span><span style="display:flex;"><span>BATCH_SIZE <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>
</span></span><span style="display:flex;"><span>filters <span style="color:#f92672">=</span> <span style="color:#ae81ff">30</span>
</span></span><span style="display:flex;"><span>kernel_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>strides <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span></code></pre></div></div></div></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.105.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2019 - 2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">Albire0</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","maxResultLength":10,"noResultsFound":"No results found","snippetLength":50}};</script><script type="text/javascript" src="/js/theme.min.25ab66029f0838f9b697628561cf55c5.js" integrity="md5-JatmAp8IOPm2l2KFYc9VxQ=="></script></body>
</html>
